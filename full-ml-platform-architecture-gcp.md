---
title: Building a Full ML Platform on GCP: The Complete Reference Architecture
subtitle: "The definitive guide to designing and automating a production-grade ML platform on Google Cloud"
slug: building-full-ml-platform-on-gcp
cover_image: 
tags: machine-learning, Terraform, google-cloud, vertex-AI, Pub/Sub
domain: israelcodes.hashnode.dev
---

# Building a Full ML Platform on GCP: The Complete Reference Architecture
---

## Introduction

If you're building machine learning at scale in Google Cloud Platform (GCP), you need more than just a trained model. You need a **complete ML platform** that can handle the entire lifecycleâ€”from data ingestion to model deployment, monitoring, and automated retraining.

This post walks through a production-ready ML platform architecture that answers the question: *"If I were building ML at scale in GCP, how do all the pieces fit together?"*

---

## ğŸ§  The High-Level Vision

A **Full ML Platform** is a system that can:

- âœ… **Ingest data automatically** from various sources
- âœ… **Trigger ML workflows via events** (no manual intervention)
- âœ… **Train models reproducibly** with full lineage tracking
- âœ… **Deploy models safely** with canary deployments and rollbacks
- âœ… **Monitor & retrain continuously** based on drift and performance
- âœ… **Be fully automated** with Infrastructure as Code (IaC) and CI/CD

All of this without clicking buttons in the console. Everything is code, version-controlled, and reproducible.

---

## ğŸ§© The Architecture: End-to-End Flow

Here's how the complete system fits together:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Sources â”‚
â”‚ (Apps, DBs)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pub/Sub      â”‚  â† events: new data, drift, retrain
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cloud        â”‚
â”‚ Functions    â”‚  â† routing + decisions
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vertex AI    â”‚
â”‚ Pipelines    â”‚  â† preprocess â†’ train â†’ evaluate
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vertex AI    â”‚
â”‚ Model Reg.   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Endpoints    â”‚  â† online inference
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Monitoring   â”‚
â”‚ & Drift      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†º (retrain loop)
```

This architecture creates a **closed-loop system** where monitoring triggers retraining, which updates models, which serve predictions, which get monitored again.

---

## ğŸ”§ What Each Layer Does (Plain English)

### 1ï¸âƒ£ Infrastructure Layer (Terraform)

**The Foundation**

This is where everything starts. All infrastructure is defined as code:

- **GCS buckets** for data storage and model artifacts
- **Pub/Sub topics** for event-driven communication
- **Service accounts & IAM** with least-privilege access
- **Cloud Functions** for orchestration
- **Vertex AI resources** for ML workloads

**Why it matters:**
- âœ… Reproducible across environments (dev, staging, prod)
- âœ… Auditable (every change is tracked in Git)
- âœ… Version-controlled (rollback is a `git revert` away)
- âœ… No manual console clicks = fewer human errors

**Example Terraform structure:**
```hcl
# Infrastructure as Code
resource "google_storage_bucket" "ml_artifacts" {
  name     = "${var.project_id}-ml-artifacts"
  location = var.region
}

resource "google_pubsub_topic" "ml_events" {
  name = "ml-events-${var.environment}"
}

resource "google_service_account" "ml_service_account" {
  account_id = "ml-sa-${var.environment}"
}
```

---

### 2ï¸âƒ£ Event Layer (Pub/Sub)

**The Nervous System**

Pub/Sub decouples all components. Events flow through topics like:

- `new_data_available` â†’ triggers data validation pipeline
- `model_drift_detected` â†’ triggers retraining workflow
- `training_completed` â†’ triggers model evaluation
- `evaluation_passed` â†’ triggers deployment

**Why it matters:**
- âœ… **Loose coupling**: Services don't need to know about each other
- âœ… **Scalability**: Handle bursts without breaking
- âœ… **Resilience**: If one component fails, others continue
- âœ… **Flexibility**: Add new consumers without changing producers

**Event-driven architecture benefits:**
```
Producer â†’ Topic â†’ Multiple Consumers
   â†“
Cloud Function A (training)
Cloud Function B (monitoring)
Cloud Function C (alerting)
```

---

### 3ï¸âƒ£ Orchestration Layer (Cloud Functions)

**The Brain**

Cloud Functions make decisions based on events:

- **Which pipeline to run?** (e.g., retrain vs. new model)
- **With what parameters?** (e.g., hyperparameters, data splits)
- **In which environment?** (dev vs. prod)

This is **business logic**, not ML code. It's the glue that connects events to ML workflows.

**Example decision logic:**
```python
def handle_ml_event(event, context):
    event_type = event['attributes']['type']
    
    if event_type == 'new_data_available':
        trigger_pipeline('data_validation')
    elif event_type == 'drift_detected':
        trigger_pipeline('retrain_model')
    elif event_type == 'training_completed':
        trigger_pipeline('evaluate_model')
```

---

### 4ï¸âƒ£ ML Workflow Layer (Vertex AI Pipelines)

**The Factory**

Vertex AI Pipelines run your ML workflows as **reproducible, versioned pipelines**:

**Typical pipeline steps:**
1. **Data validation** â†’ Check data quality, schema compliance
2. **Feature engineering** â†’ Transform raw data into features
3. **Model training** â†’ Train with tracked hyperparameters
4. **Evaluation** â†’ Compute metrics (accuracy, precision, recall)
5. **Registration** â†’ Store model in registry if metrics pass

**Why Vertex AI Pipelines:**
- âœ… **Reproducibility**: Same inputs = same outputs (guaranteed)
- âœ… **Tracking**: Every run is logged with parameters and metrics
- âœ… **Versioning**: Pipeline code is versioned, runs are tracked
- âœ… **Parallelization**: Steps run in parallel when possible
- âœ… **Cost optimization**: Only pay for compute time used

**Pipeline example (Kubeflow):**
```python
@dsl.pipeline(
    name='ml-training-pipeline',
    description='End-to-end ML training workflow'
)
def ml_pipeline(
    input_data: str,
    model_name: str
):
    validate = validate_data_op(input_data)
    features = engineer_features_op(validate.output)
    train = train_model_op(features.output)
    evaluate = evaluate_model_op(train.output)
    register = register_model_op(
        evaluate.output,
        model_name=model_name
    )
```

---

### 5ï¸âƒ£ Model Management (Vertex AI Model Registry)

**The Catalog**

Every model version is stored with:

- **Model artifacts** (weights, metadata)
- **Training metrics** (accuracy, loss curves)
- **Evaluation results** (test set performance)
- **Lineage** (which data, code, and parameters produced it)
- **Tags** (production, staging, experimental)

**Why it matters:**
- âœ… **No more confusion**: "Which model is live?"
- âœ… **Easy rollbacks**: Revert to previous version in seconds
- âœ… **Compliance**: Full audit trail for regulated industries
- âœ… **Experimentation**: Compare model versions side-by-side

**Model registry workflow:**
```
Training â†’ Evaluation â†’ Registration â†’ Deployment
   â†“           â†“            â†“            â†“
  v1.0       metrics      v1.0        staging
  v1.1       metrics      v1.1        production
  v2.0       metrics      v2.0        canary
```

---

### 6ï¸âƒ£ Serving Layer (Vertex AI Endpoints)

**The Product**

This is what your applications actually hit for predictions:

**Features:**
- **Online inference** â†’ Sub-100ms latency
- **Autoscaling** â†’ Handles traffic spikes automatically
- **Canary deployments** â†’ Gradual rollout (10% â†’ 50% â†’ 100%)
- **A/B testing** â†’ Compare model versions in production
- **Traffic splitting** â†’ Route X% to model A, Y% to model B

**Why Vertex AI Endpoints:**
- âœ… **Managed infrastructure**: No server management
- âœ… **High availability**: 99.9% uptime SLA
- âœ… **Cost-effective**: Pay per prediction
- âœ… **Security**: IAM-based access control

**Deployment strategy:**
```
New Model â†’ Canary (10%) â†’ Gradual Rollout â†’ Full Production
              â†“
         Monitor metrics
              â†“
    If good: increase traffic
    If bad: rollback immediately
```

---

### 7ï¸âƒ£ Monitoring & Feedback Loop

**The Immune System**

This closes the MLOps loop:

**What gets monitored:**
- **Prediction logging** â†’ Every prediction is logged
- **Data drift detection** â†’ Input distribution changes
- **Performance decay** â†’ Model accuracy degrades over time
- **Latency & errors** â†’ Serving infrastructure health

**Automatic triggers:**
- Data drift detected â†’ Trigger retraining pipeline
- Performance below threshold â†’ Alert + retrain
- Error rate spike â†’ Alert + investigate

**Monitoring architecture:**
```
Predictions â†’ Cloud Logging â†’ Monitoring Dashboard
     â†“
Drift Detection Service
     â†“
Pub/Sub Event: "drift_detected"
     â†“
Cloud Function â†’ Trigger Retraining
```

---

## ğŸ” Security & Governance (Critical)

Security is **not optional** in production ML systems. Here's what needs to be in place:

### Service Account Strategy

- **Separate service accounts** for each component
- **Least-privilege IAM** â†’ Only grant what's needed
- **No long-lived secrets** â†’ Use Workload Identity

### Environment Isolation

- **Dev/Staging/Prod** â†’ Completely separate resources
- **Network isolation** â†’ VPCs, private endpoints
- **Data isolation** â†’ Separate buckets, databases

### CI/CD Security

- **Approval gates** â†’ Require reviews for production
- **Automated testing** â†’ Validate before deployment
- **Secrets management** â†’ Use Secret Manager, not hardcoded values

### IAM Best Practices

```hcl
# Example: Least-privilege IAM
resource "google_project_iam_member" "ml_service_account" {
  project = var.project_id
  role    = "roles/aiplatform.user"  # Only what's needed
  member  = "serviceAccount:${google_service_account.ml_service_account.email}"
}
```

**Why this matters:**
- A breach in one component doesn't compromise the entire system
- Compliance requirements (GDPR, HIPAA) are easier to meet
- Audits are straightforward (everything is in Terraform)

---

## ğŸ“Š Architecture Diagram (Detailed)

Here's a more detailed view of how components interact:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Sources Layer                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚   Apps   â”‚  â”‚   DBs    â”‚  â”‚  APIs    â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      Pub/Sub Topics          â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚  â”‚  ml-events            â”‚   â”‚
        â”‚  â”‚  data-ingestion       â”‚   â”‚
        â”‚  â”‚  model-updates        â”‚   â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    Cloud Functions           â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚  â”‚  Event Router         â”‚   â”‚
        â”‚  â”‚  Pipeline Trigger     â”‚   â”‚
        â”‚  â”‚  Decision Logic       â”‚   â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Vertex AI Pipelines       â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚  â”‚  Data Validation      â”‚   â”‚
        â”‚  â”‚  Feature Engineering â”‚   â”‚
        â”‚  â”‚  Model Training      â”‚   â”‚
        â”‚  â”‚  Evaluation          â”‚   â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Vertex AI Model Registry   â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚  â”‚  Model Versions       â”‚   â”‚
        â”‚  â”‚  Metadata & Metrics   â”‚   â”‚
        â”‚  â”‚  Lineage Tracking     â”‚   â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Vertex AI Endpoints        â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚  â”‚  Online Inference     â”‚   â”‚
        â”‚  â”‚  Autoscaling          â”‚   â”‚
        â”‚  â”‚  Canary Deployments   â”‚   â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Monitoring & Observability â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚  â”‚  Prediction Logging  â”‚   â”‚
        â”‚  â”‚  Drift Detection      â”‚   â”‚
        â”‚  â”‚  Performance Metrics  â”‚   â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†º (feedback loop)
```
---

## ğŸ’¡ Key Takeaways

1. **Infrastructure as Code is non-negotiable** â†’ Terraform everything
2. **Event-driven architecture scales** â†’ Pub/Sub decouples everything
3. **Reproducibility is built-in** â†’ Vertex AI Pipelines track everything
4. **Security is layered** â†’ Service accounts, IAM, network isolation
5. **Monitoring closes the loop** â†’ Automated retraining based on drift

---

## ğŸ“š Additional Resources

- [Vertex AI Pipelines Documentation](https://cloud.google.com/vertex-ai/docs/pipelines)
- [Cloud Functions Best Practices](https://cloud.google.com/functions/docs/best-practices)
- [MLOps on GCP Guide](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)
- [Terraform GCP Provider](https://registry.terraform.io/providers/hashicorp/google/latest/docs)

---

## Conclusion

Building a full ML platform on GCP is complex, but it's also **incredibly valuable** for your career. This architecture gives you:

- âœ… **Production-ready patterns** you can use immediately
- âœ… **Interview talking points** that demonstrate deep understanding
- âœ… **Portfolio projects** that stand out from basic ML tutorials
- âœ… **Real-world experience** with enterprise-grade systems

The key is to **start simple** and **iterate**. Don't try to build everything at once. Pick one component, get it working, then add the next layer.

**Remember:** The best ML platform is the one that ships models to production reliably, not the one with the most features.

---

*Have questions or want to discuss this architecture? Reach out on [Hashnode](https://israelcodes.hashnode.dev) or connect on [LinkedIn](https://linkedin.com/in/Aloagbaye).*

---

**Tags:** #MachineLearning #MLOps #GCP #CloudArchitecture #Terraform #VertexAI #DevOps
